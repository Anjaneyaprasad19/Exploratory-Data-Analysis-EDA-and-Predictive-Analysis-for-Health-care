{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bharg\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\bharg\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the cleaned healthcare dataset\n",
    "data = pd.read_csv('Cleaned_healthcare_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop(columns=['Test Results_0', 'Test Results_1', 'Test Results_2', 'Name', 'Date of Admission', 'Discharge Date'])\n",
    "y = data[['Test Results_0', 'Test Results_1', 'Test Results_2']].idxmax(axis=1)  # Revert one-hot encoding to class labels\n",
    "y = y.map({'Test Results_0': 'Normal', 'Test Results_1': 'Abnormal', 'Test Results_2': 'Inconclusive'})\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bharg\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n",
      "Accuracy: 0.9008823529411765\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.30      0.11      0.16       887\n",
      "Inconclusive       0.90      0.97      0.94      7566\n",
      "      Normal       1.00      1.00      1.00      1747\n",
      "\n",
      "    accuracy                           0.90     10200\n",
      "   macro avg       0.74      0.69      0.70     10200\n",
      "weighted avg       0.87      0.90      0.88     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine the one-hot encoded columns into a single target variable\n",
    "# This will assign a label based on the index of the column with a value of 1\n",
    "y = data[['Test Results_0', 'Test Results_1', 'Test Results_2']].idxmax(axis=1)\n",
    "\n",
    "# Map the column names back to original class labels if desired (optional)\n",
    "y = y.map({'Test Results_0': 'Normal', 'Test Results_1': 'Abnormal', 'Test Results_2': 'Inconclusive'})\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bharg\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with SMOTE Results\n",
      "Accuracy: 0.9406701909214032\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.94      0.88      0.91      7572\n",
      "Inconclusive       0.89      0.94      0.91      7764\n",
      "      Normal       1.00      1.00      1.00      7553\n",
      "\n",
      "    accuracy                           0.94     22889\n",
      "   macro avg       0.94      0.94      0.94     22889\n",
      "weighted avg       0.94      0.94      0.94     22889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split resampled data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model on SMOTE-balanced data\n",
    "logistic_model_smote = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "logistic_model_smote.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_smote = logistic_model_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression with SMOTE Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\bharg\\anaconda3\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bharg\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       1.00      1.00      1.00      7572\n",
      "Inconclusive       1.00      1.00      1.00      7764\n",
      "      Normal       1.00      1.00      1.00      7553\n",
      "\n",
      "    accuracy                           1.00     22889\n",
      "   macro avg       1.00      1.00      1.00     22889\n",
      "weighted avg       1.00      1.00      1.00     22889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Results\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7561\n",
      "           1       1.00      1.00      1.00      7564\n",
      "           2       1.00      1.00      1.00      7764\n",
      "\n",
      "    accuracy                           1.00     22889\n",
      "   macro avg       1.00      1.00      1.00     22889\n",
      "weighted avg       1.00      1.00      1.00     22889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the Gradient Boosting model\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM) Results\n",
      "Accuracy: 0.943247848311416\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       1.00      0.83      0.91      7572\n",
      "Inconclusive       0.86      1.00      0.92      7764\n",
      "      Normal       1.00      1.00      1.00      7553\n",
      "\n",
      "    accuracy                           0.94     22889\n",
      "   macro avg       0.95      0.94      0.94     22889\n",
      "weighted avg       0.95      0.94      0.94     22889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Support Vector Machine (SVM) Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
