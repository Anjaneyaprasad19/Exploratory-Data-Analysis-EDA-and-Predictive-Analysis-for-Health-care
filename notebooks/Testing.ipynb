{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before preprocessing: 1000\n",
      "Rows after preprocessing: 1000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.32      0.19      0.24       319\n",
      "Inconclusive       0.29      0.09      0.14       360\n",
      "      Normal       0.33      0.72      0.45       321\n",
      "\n",
      "    accuracy                           0.32      1000\n",
      "   macro avg       0.31      0.33      0.28      1000\n",
      "weighted avg       0.31      0.32      0.27      1000\n",
      "\n",
      "Accuracy: 0.32\n",
      "Confusion Matrix:\n",
      "[[ 60  39 220]\n",
      " [ 76  33 251]\n",
      " [ 51  40 230]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the new dataset\n",
    "new_dataset_path = \"Test_Dataset.csv\"  # Replace with your new dataset path\n",
    "new_data = pd.read_csv(new_dataset_path)\n",
    "\n",
    "# Load the trained model, scaler, and encoders\n",
    "model = joblib.load(\"random_forest_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "\n",
    "# Preprocess the new dataset\n",
    "categorical_features = ['Gender', 'Blood Type', 'Medical Condition', 'Medication']\n",
    "for feature in categorical_features:\n",
    "    encoder = label_encoders[feature]\n",
    "    if 'Unknown' in encoder.classes_:\n",
    "        new_data[feature] = new_data[feature].map(\n",
    "            lambda x: encoder.transform([x])[0] if np.isin(x, encoder.classes_) else encoder.transform(['Unknown'])[0]\n",
    "        )\n",
    "    else:\n",
    "        # Map unseen values to the most frequent class (fallback)\n",
    "        most_frequent_class = encoder.transform([encoder.classes_[0]])[0]\n",
    "        new_data[feature] = new_data[feature].map(\n",
    "            lambda x: encoder.transform([x])[0] if np.isin(x, encoder.classes_) else most_frequent_class\n",
    "        )\n",
    "\n",
    "# Validate processed data\n",
    "print(f\"Rows before preprocessing: {len(new_data)}\")\n",
    "new_data = new_data.dropna()  # Drop rows with nulls in non-categorical fields\n",
    "print(f\"Rows after preprocessing: {len(new_data)}\")\n",
    "\n",
    "# Prepare features\n",
    "features = ['Age', 'Gender', 'Blood Type', 'Medical Condition', 'Medication']\n",
    "X_new = new_data[features]\n",
    "\n",
    "# Encode the target if it exists in the new dataset\n",
    "if 'Test Results' in new_data.columns:\n",
    "    y_new = new_data['Test Results']\n",
    "    # Map target values to numeric labels\n",
    "    valid_targets = label_encoders['Test Results'].classes_\n",
    "    y_new = y_new.map(\n",
    "        lambda x: label_encoders['Test Results'].transform([x])[0] if np.isin(x, valid_targets) else None\n",
    "    )\n",
    "    # Drop rows with invalid target labels (None)\n",
    "    new_data = new_data.dropna(subset=['Test Results'])\n",
    "    # Convert valid target labels to numeric format\n",
    "    y_new = label_encoders['Test Results'].transform(new_data['Test Results'])\n",
    "else:\n",
    "    y_new = None  # Ground truth not available\n",
    "\n",
    "# Scale numerical features\n",
    "if len(X_new) > 0:  # Ensure dataset is not empty\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_new_scaled)\n",
    "\n",
    "    if y_new is not None:\n",
    "        # Evaluate the model if ground truth is available\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_new, y_pred, target_names=[str(cls) for cls in label_encoders['Test Results'].classes_]))\n",
    "        print(f\"Accuracy: {accuracy_score(y_new, y_pred):.2f}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_new, y_pred)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "    else:\n",
    "        # Print predictions if ground truth is not available\n",
    "        print(\"Predictions for the new dataset:\")\n",
    "        print(pd.DataFrame({'Predicted': label_encoders['Test Results'].inverse_transform(y_pred)}))\n",
    "else:\n",
    "    print(\"No valid rows in the new dataset after preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
